\input{prelude.tex}
\input{config.tex}



%\author
%{John Smith,$^{1\ast}$ Jane Doe,$^{1}$ Joe Scientist$^{2}$\\
%\\
%\normalsize{$^{1}$Department of Chemistry, University of Wherever,}\\
%\normalsize{An Unknown Address, Wherever, ST 00000, USA}\\
%\normalsize{$^{2}$Another Unknown Address, Palookaville, ST 99999, USA}\\
%\\
%\normalsize{$^\ast$To whom correspondence should be addressed; E-mail:  jsmith@wherever.edu.}
%}



%%%%%%%%%%%%%%%%% END OF PREAMBLE %%%%%%%%%%%%%%%%



% Double-space the manuscript.


% Make the title.



\begin{document}
\maketitle

%\include{Sections/Introduzione.tex}
%\include{Section2}
%\include{Section3}
%\include{Section4}
%\include{Conclusion}

%*******    Figure and Subfigure example ***********
%\begin{figure}[tbh]
% \includegraphics[width=1\linewidth]{circle}
% \caption[Circonferenza]{Circle}
% \label{fig:circle}
% \end{figure}%

% \begin{figure}[tbh]
% \begin{subfigure}{.5\textwidth}
% \includegraphics[width=1\linewidth]{circle}
% \caption[Circonferenza]{Circle}
% \label{fig:circle}
% \end{subfigure}%
% \begin{subfigure}{0.5\textwidth}
% \includegraphics[width=1\linewidth]{random}
% \caption[Random]{Random}
% \label{fig:random}
% \end{subfigure}
% \end{figure}
%%%***************************************%%



% Place your abstract within the special {sciabstract} environment.




% In setting up this template for *Science* papers, we've used both
% the \section* command and the \paragraph* command for topical
% divisions.  Which you use will of course depend on the type of paper
% you're writing.  Review Articles tend to have displayed headings, for
% which \section* is more appropriate; Research Articles, when they have
% formal topical divisions at all, tend to signal them with bold text
% that runs into the paragraph, for which \paragraph* is the right
% choice.  Either way, use the asterisk (*) modifier, as shown, to
% suppress numbering.

\section{Data Size Analysis}
The main bottleneck of the basic algorithm is memory. With only 1GB of available memory and binary files to load for a total of ~5.6GB (\texttt{person, interest and knows maps}) we first analyzed the query to look for ways to drop unnecessary data. The possible optimization we found were:
\begin{enumerate}
    \item Consider only relationships between people in the same location: the query searches for friendships of people that live in the same city, while the \texttt{knows} file contains all relationships. By removing those between people in different cities we both reduce the size of the data we have to look into and the computation cost of searching through friendships that are not important for the results of the query;
    \item Consider only mutual friendships: each person can have a knows relationship with each other but this is unilateral. Since the query asks for only mutual relationships between two person (if P1,P2 are two persons, then in the \texttt{knows map} we can find both P1->P2 and P2->P1) we drop all single relationships between people;
    \item Remove people that don't have any mutual friendship with someone in the same city: it follows directly from the steps above, these type of people are not useful because they will surely not be result of the query.
\end{enumerate}
After applying these optimizations we created the files:
\begin{itemize}
    \item \texttt{knows\_location}: original knows that contains only relationships between people in the same location;
    \item \texttt{person\_location}: person map with updated indexes knows\_first and knows\_n to reflect the knows\_location;
    \item \texttt{knows\_mutual}: knows relationships only between people that know each other;
    \item \texttt{person\_mutual}: person map that contains only people that have at least a mutual friendship in the same location and has the correct indexes knows\_first and knows\_n (for the knows\_mutual);
\end{itemize}


\section{Interests inverted table}
In the basic implementation we compute the scores of each person by reading all his list of artists, checking if they like the artists that are present int the query. In the majority of the cases the person doesn't like the artists of the query or likes also a lot of other artists. This means that we read and check a lot of interests that aren't useful for the current query. We decided to optimize the computation of the scores by creating an inverted table between artists and person. In the inverted table, for each artist, there is a list of people that likes the artist.
In this way we can access directly to the lists of artists of the query.
\par One problem in implementing this inverted table is that the memory (1GB) is not enough to contain all the connections between artists and person. For this reason we decided to compute the inverted table in multiple steps, considering in each step only a portion of the total number of artists. In this way the usage of the memory and the swapping to disk are reduced.
After the computation the following files are created:
\begin{itemize}
\item \texttt{artists}: table with all the different artists. Each entry has an id of the artists, the position in the inverted table where starts his list and a field that indicates the length of the list;
\item \texttt{likedBy}: this file is the inverted table, it contains only one field that indicates the offset of the person in person table.
\end{itemize}


\section{Birthday ordering}
In the naive implementation we run through the entire \texttt{person\_map} and check every time if the current person has the birthday in the range of the query. We decided to optimize the access to the data by ordering the person by birthday. We had two options: order the people in the data structure (and update the indexes contained in the interests and knows files) or create a new index containing the position of the person and its birthday and then order it. We decided to go for the latter that was easier to implement without modifying the other data structures but has the disadvantage that it uses more memory. \\
In the cruncher, we use the birthday index to first search the first occurrence of a person with a birthday in the range required by the current query, then we know all the people inside the range follows the first one until we reach someone with a birthday that is out of the bound.

\section{Data Structures}

\begin{figure}[tbh]
\includegraphics[width=1\linewidth]{data}
\caption[Data]{Data Structures}
\label{fig:data}
\end{figure}

In figure \ref{fig:data} we show the data structure used by the cruncher to perform the queries. The intermediate files created are not shown in the figure. Since we use a different table for the people's birthdays and the interests table now has a reference to the person's one, we decided to drop the birthday, interest\_first and interest\_n fields from the Person data type to reduce even more the total size.


\section{Cruncher}
The computations of query inside the cruncher is split in two phases:
\begin{itemize}
\item Precomputation of the scores: to compute the score we make use of the files \texttt{artists} and \texttt{likedBy}. To search the artists of the current query we just need to go through the artists table one time. When an artist is found we update the scores of the people that are inside the list of the artist;
\item Computation of the query: to compute the query we run through the people that have their birthday in the interval required by the query. To go through only those people we leverage the birthday index, performing a binary search of the person that have the lowest birthday that is inside the interval required by the query.\par Other important  aspect of the computation of the query is that there is no more the need to check the location and the mutual friendship. By removing the mutual friendship check the non-sequential access to the knows table is avoided. On the other hand the non-sequential access to the person table to get the information about the friend is still present in the cruncher but it doesn't slow down the performance because the reduced person table fits in memory, so there isn't access to disk to retrieve the friend. 
\end{itemize}  

\section{Possible improvements}
\begin{itemize}
    \item To save the relationships between people we use a person table that contains all the people and a knows table that has the offsets to the person table. Another way to obtain the same result would be to use a unified table of couples with two person\_id for each entry. This would improve the sequential access to the data (the id of two person who are friend are always close to each other) 
    \item Instead of using a secondary file to index the birthdays we could have ordered the people in the data structures to reduce the memory usage;
    \item For each query, we load the \texttt{artists} and \texttt{likedBy} files to calculate the scores for the query in questions. We could calculate the scores for all the queries (or for a bunch of them) at a time and store them in an array (the number of queries should be small enough to avoid occupying too much memory with this array) so that we wouldn't need to access those files frequently;
    \item An alternative to the a\texttt{artists} and \texttt{likedBy} files we use would be to create a bit array of size \texttt{number\_of\_person * number\_of\_interests} where each bit set to 1 if a person likes an artist. In a scenario where the amount of 1s is around half of the total (each person on average likes half of the artists) this would be a good way to compact the data. In this case we found that each person likes only a few of the artists available, so implementing the bit array would have led to a structure filled with mostly 0s. 
\end{itemize}





\clearpage

%\bibbycategory % equivale a dare un \printbibliography per ogni categoria

\end{document}
